{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>  ü¶ô –§–∞–π–Ω—Ç—é–Ω–∏–Ω–≥ –±–æ–ª—å—à–∏—Ö —è–∑—ã–∫–æ–≤—ã—Ö –º–æ–¥–µ–ª–µ–π üéõ</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üßë‚Äçüéì –í —ç—Ç–æ–º —É—Ä–æ–∫–µ: \n",
    "<img src='../images/finetune_vs_rag.webp' align=\"right\" width=\"450\" height=\"400\">\n",
    "\n",
    "* üé≤ –†–∞–∑–±–µ—Ä–µ–º—Å—è, –∑–∞—á–µ–º –∏ –∫–æ–≥–¥–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥ (fine-tuning)\n",
    "* [ü§π‚Äç‚ôÄÔ∏è –ù–∞—É—á–∏–º—Å—è –≥–æ—Ç–æ–≤–∏—Ç—å –¥–∞—Ç–∞—Å–µ—Ç—ã –¥–ª—è —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞](#part2)\n",
    "* [üöÄ –ü–æ–π–º–µ–º, –∫–∞–∫ –æ—Å—É—â–µ—Å—Ç–≤–∏—Ç—å –¥–æ–æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ–º–æ—â—å—é —Ñ—Ä—ç–π–º–≤–æ—Ä–∫–∞ [unsloth](https://github.com/unslothai/unsloth)](#part3)\n",
    "* [üì¶üë©‚Äçüíª –û—Å–≤–æ–∏–º —Ç–µ—Ö–Ω–∏–∫–∏ —ç—Ñ—Ñ–µ–∫—Ç–∏–≤–Ω–æ–≥–æ —Ñ–∞–Ω—Ç—é–Ω–∞ (**Peft**, **Lora**, **QLora** –∏ –ø—Ä–æ—á–∏–µ –Ω–µ–ø—Ä–∏–ª–∏—á–Ω—ã–µ –∞–±–±—Ä–µ–≤–∏–∞—Ç—É—Ä—ã)](#part4)\n",
    "* [üì¶ –ü—Ä–æ–∏–∑–≤–µ–¥–µ–º –∏–Ω—Ñ–µ—Ä–µ–Ω—Å –∏ –ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –¥–æ–æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏ ](#part4)\n",
    "*  ü•ä [–†–∞–∑–±–µ—Ä—ë–º —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥ –Ω–∞ –ø—Ä–∏–º–µ—Ä–µ 2-—Ö –¥–∞—Ç–∞—Å–µ—Ç–æ–≤:](#part6)\n",
    "    *  –°–æ–±–µ—Ä–∞—Ç—å —Å–≤–æ–π\n",
    "    *  –∏–ª–∏ –≤–∑—è—Ç—å –≥–æ—Ç–æ–≤—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å HF [—Å—Ç–∞—Ç—å—è –Ω–∞ –•–∞–±—Ä](https://habr.com/ru/articles/832984/)\n",
    "*  [üß∏ –í—ã–≤–æ–¥—ã –∏ –∑–∞–∫–ª—é—á–µ–Ω–∏—è ‚úÖ](#part6)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**üöÄ –î–æ–æ–±—É—á–∞—Ç—å –ø—Ä–æ—â–µ, —á–µ–º –∫–∞–∂–µ—Ç—Å—è!`**\n",
    "    \n",
    "<img src='../images/lamauns.png' align=\"right\" width=\"350\" height=\"478\" >\n",
    "\n",
    "* –ß—Ç–æ–±—ã –∑–∞–ø—É—Å—Ç–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞ –Ω–∞ —Ä–µ—Å—É—Ä—Å–∞—Ö Google Colab –∏ –Ω–µ –∂–¥–∞—Ç—å –≤–µ—á–Ω–æ—Å—Ç—å. <br>\n",
    "* –í–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã–º  —Ñ—Ä—ç–π–º–≤–æ—Ä–∫–æ–º [Unsloth](https://github.com/unslothai/unsloth), –∫–æ—Ç–æ—Ä—ã–π –ø–æ–∑–≤–æ–ª—è–µ—Ç —É—Å–∫–æ—Ä–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞ –æ—Ç 2-—Ö –¥–æ 5 —Ä–∞–∑ –Ω–∞ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å—Å–∫–∏—Ö –≤–∏–¥–µ–æ–∫–∞—Ä—Ç–∞—Ö (–∏ –¥–∞–∂–µ –Ω–∞ CPU), –∏ —Ç—Ä–µ–±—É–µ—Ç –º–µ–Ω—å—à–µ –ø–∞–º—è—Ç–∏.\n",
    "* –ù–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ –ø—Ä–æ–µ–∫—Ç–∞ –µ—Å—Ç—å –≥–æ—Ç–æ–≤—ã–µ —É–¥–æ–±–Ω—ã–µ –Ω–æ—É—Ç–±—É–∫–∏ c —Ä–∞–∑–±–æ—Ä–æ–º —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞ —Å–∞–º—ã—Ö –ø–æ–ø—É–ª—è—Ä–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π - –Ω–∞ –±–∞–∑–µ –æ–¥–Ω–æ–≥–æ –∏–∑ –Ω–∏—Ö –º—ã —Å–¥–µ–ª–∞–ª–∏ —ç—Ç–æ—Ç –Ω–æ—É—Ç–±—É–∫. \n",
    "* –¢–∞–∫ –∂–µ —Ñ—Ä–µ–π–º–≤–æ—Ä–∫ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–∞–ø—É—Å–∫–∞—Ç—å —Ñ–∞–π–Ω—Ç—é–Ω –±–µ–∑ –≥–ª—É–±–æ–∫–∏—Ö –∑–Ω–∞–Ω–∏–π –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π –∏ ML."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# –£—Å—Ç–∞–Ω–æ–≤–∏–º unsloth –∏ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2eSvM9zX_2d3"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# —É—Å—Ç–∞–Ω–æ–≤–∫–∞ Unsloth, Xformers (Flash Attention) –∏ –≤—Å–µ –¥—Ä—É–≥–∏–µ –ø–∞–∫–µ—Ç—ã!\n",
    "!pip install \"unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git\"\n",
    "\n",
    "#–ù–∞–º –Ω—É–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –∫–∞–∫–∞—è –≤–µ—Ä—Å–∏—è Torch –¥–ª—è Xformers (2.3 -> 0.0.27)\n",
    "from torch import __version__; from packaging.version import Version as V\n",
    "xformers = \"xformers==0.0.27\" if V(__version__) < V(\"2.4.0\") else \"xformers\"\n",
    "!pip install --no-deps {xformers} trl peft accelerate bitsandbytes triton"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "–ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –∏ –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä—É—é –±—É–¥–µ–º —Ñ–∞–π–Ω—Ç—é–Ω–∏—Ç—å - `Llama-3.1-8B`. <br>\n",
    "–í –ª–æ–≥–∞—Ö —É–≤–∏–¥–∏–º, —á—Ç–æ **Unsloth** –ø—Ä–æ–ø–∞—Ç—á–∏–ª –Ω–∞—à—É —Å–∏—Å—Ç–µ–º—É –¥–ª—è –¥–≤—É–∫—Ä–∞—Ç–Ω–æ–≥–æ —É—Å–∫–æ—Ä–µ–Ω–∏—è –ø—Ä–æ—Ü–µ—Å—Å–∞."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QmUBVEnvCDJv",
    "outputId": "9d79f0f1-c3c3-44f2-df15-2f15a5e77216"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü¶• Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "==((====))==  Unsloth 2024.8: Fast Llama patching. Transformers = 4.44.2.\n",
      "   \\\\   /|    GPU: Tesla T4. Max memory: 14.748 GB. Platform = Linux.\n",
      "O^O/ \\_/ \\    Pytorch: 2.4.0+cu121. CUDA = 7.5. CUDA Toolkit = 12.1.\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.27.post2. FA2 = False]\n",
      " \"-____-\"     Free Apache license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n"
     ]
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel\n",
    "import torch\n",
    "\n",
    "max_seq_length = 2048 # Choose any! We auto support RoPE Scaling internally!\n",
    "dtype = None          # None for auto detection. Float16 for Tesla T4, V100, Bfloat16 for Ampere+\n",
    "load_in_4bit = True   # Use 4bit quantization to reduce memory usage. Can be False.\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"unsloth/Meta-Llama-3.1-8B\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dtype = dtype,\n",
    "    load_in_4bit = load_in_4bit, # –ü—Ä–∏–º–µ–Ω—è–µ–º QLoRA\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "    \n",
    "–ò—Å–ø–æ–ª—å–∑—É–µ–º—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã:\n",
    "* `model_name` - –∏–º—è –º–æ–¥–µ–ª–∏ –¥–ª—è —Ñ–∞–π–Ω—Ç—é–Ω–∞ (—Å–º–æ—Ç—Ä–∏–º –¥–æ—Å—Ç—É–ø–Ω—ã–µ [–∑–¥–µ—Å—å](https://github.com/unslothai/unsloth))\n",
    "* `max_seq_length` - –º–∞–∫—Å–∏–º–∞–ª—å–Ω–∞—è –¥–ª–∏–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –≤ —Ç–æ–∫–µ–Ω–∞—Ö.\n",
    "* `dtype` - –¢–∏–ø –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Ö—Ä–∞–Ω–µ–Ω–∏—è –≤–µ—Å–æ–≤ (–∑–∞–≤–∏—Å–∏—Ç –æ—Ç –º–æ–¥–µ–ª–∏ –≤–∏–¥–µ–æ–∫–∞—Ä—Ç—ã). –î–ª—è –∞—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–≥–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Å—Ç–∞–≤–∏—Ç—å `None`.\n",
    "* `load_in_4bit` - –∫–ª—é—á–µ–≤–æ–π –ø–∞—Ä–∞–º–µ—Ç—Ä –¥–ª—è –ø–æ–¥–≥—Ä—É–∑–∫–∏ 4-—Ö –±–∏—Ç–Ω–æ–π –≤–µ—Ä—Å–∏–∏ –º–æ–¥–µ–ª–∏. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXd9bTZd1aaL"
   },
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "üî• –ß—Ç–æ–±—ã –Ω–µ –ø–µ—Ä–µ—É—á–∏–≤–∞—Ç—å –ø–æ–ª–Ω–æ—Å—Ç—å—é –≤—Å—é –º–æ–¥–µ–ª—å - –±—É–¥–µ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å **PEFT** —Å **LoRA**. –¢–∞–∫ –º—ã –±—É–¥–µ–º –æ–±–Ω–æ–≤–ª—è—Ç—å –æ—Ç 1 –¥–æ 10% –æ—Ç –≤—Å–µ—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6bZsfBuZDeCL",
    "outputId": "2872e6db-5237-4658-9e3f-4b991a13a9d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2024.8 patched 32 layers with 32 QKV layers, 32 O layers and 32 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = 16, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "                      \"gate_proj\", \"up_proj\", \"down_proj\",],\n",
    "    lora_alpha = 16,\n",
    "    lora_dropout = 0, # Supports any, but = 0 is optimized\n",
    "    bias = \"none\",    # Supports any, but = \"none\" is optimized\n",
    "    # [NEW] \"unsloth\" uses 30% less VRAM, fits 2x larger batch sizes!\n",
    "    use_gradient_checkpointing = \"unsloth\", # True or \"unsloth\" for very long context\n",
    "    random_state = 3407,\n",
    "    use_rslora = False,  # We support rank stabilized LoRA\n",
    "    loftq_config = None, # And LoftQ\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SXd9bTZd1aaL"
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "–î–ª—è 90% —Å–ª—É—á–∞–µ–≤, –≤–∞–º –ø–æ–¥–æ–π–¥—É—Ç –∑–Ω–∞—á–µ–Ω–∏—è –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –ø–æ —É–º–æ–ª—á–∞–Ω–∏—é, –º–æ–∂–Ω–æ —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–∏—Ä–æ–≤–∞—Ç—å —Ç–æ–ª—å–∫–æ —Å –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–º `r`. –ü–æ–ª–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –≤—Å–µ—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –º–æ–∂–Ω–æ –Ω–∞–π—Ç–∏ [–∑–¥–µ—Å—å](https://docs.unsloth.ai/basics/lora-parameters-encyclopedia).\n",
    "\n",
    "–í–∞–∂–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã LoRA:\n",
    "* `r` (—Ä–∞–Ω–≥ –º–∞—Ç—Ä–∏—Ü—ã) - —Å–∞–º—ã–π –≤–∞–∂–Ω—ã–π –ø–∞—Ä–∞–º–µ—Ç—Ä, –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç —Ä–∞–∑–º–µ—Ä –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –º–∞—Ç—Ä–∏—Ü—ã (–∞–¥–∞–ø—Ç–µ—Ä–∞), –∫–æ—Ç–æ—Ä—É—é –º—ã –±—É–¥–µ–º –æ–±—É—á–∞—Ç—å –≤ –ø—Ä–æ—Ü–µ—Å—Å–µ —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞ (—Ä–µ–∫–æ–º–µ–Ω–¥—É–µ—Ç—Å—è –≤—ã–±–∏—Ä–∞—Ç—å –∫—Ä–∞—Ç–Ω–æ —Å—Ç–µ–ø–µ–Ω—è–º –¥–≤–æ–π–∫–∏ - 8, 16, 32 –∏.—Ç.–¥). –¢–∞–∫ –∂–µ –æ—Ç —ç—Ç–æ–≥–æ –ø–∞—Ä–∞–º–∞–µ—Ç—Ä–∞ –∑–∞–≤–∏—Å–∏—Ç –≤—Ä–µ–º—è –∫–æ—Ç–æ—Ä–æ–µ –±—É–¥–µ—Ç –∑–∞—Ç—Ä–∞—á–µ–Ω–æ –Ω–∞ —Ñ–∞–π–Ω—Ç—é–Ω, —á–µ–º –±–æ–ª—å—à–µ r, —Ç–µ–º –±–æ–ª—å—à–µ –≤—Ä–µ–º—è.\n",
    "* `target_modules` - —Ü–µ–ª–µ–≤—ã–µ –º–æ–¥—É–ª–∏, –≤–µ—Å–∞ –∫–æ—Ç–æ—Ä—ã—Ö –±—É–¥—É—Ç –º–µ–Ω—è—Ç—å—Å—è –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vITh0KVJ10qX"
   },
   "source": [
    "# <center id=\"part2\">  ü§π‚Äç‚ôÄÔ∏è –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞\n",
    "\n",
    "–î–ª—è —Ñ–∞–π–Ω—Ç—é–Ω–∞ –õ–∞–º—ã, —Ç—Ä–µ–±—É–µ—Ç—Å—è –ø–µ—Ä–µ–≤–µ—Å—Ç–∏ –∫–∞–∂–¥—É—é –∑–∞–ø–∏—Å—å –∏–∑ –Ω–∞—à–µ–≥–æ –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç `Alpaca prompt`.\n",
    "\n",
    "–ò –æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ –≤ –∫–æ–Ω—Ü–µ –ø—Ä–æ–º–ø—Ç–∞ –¥–æ–±–∞–≤–ª—è–µ–º —Ç–æ–∫–µ–Ω –∫–æ–Ω—Ü–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ (`EOS-token`), —á—Ç–æ–±—ã –∏–∑–±–µ–∂–∞—Ç—å –±–µ—Å–∫–æ–Ω–µ—á–Ω–æ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "LjY75GoYUCB8"
   },
   "outputs": [],
   "source": [
    "alpaca_prompt = \"\"\"Below is an instruction that describes a task, paired with an input that provides further context. \n",
    "Write a response that appropriately completes the request.\n",
    "\n",
    "### Instruction:\n",
    "{}\n",
    "\n",
    "### Input:\n",
    "{}\n",
    "\n",
    "### Response:\n",
    "{}\"\"\"\n",
    "\n",
    "EOS_TOKEN = tokenizer.eos_token # Must add EOS_TOKEN\n",
    "\n",
    "# –§—É–Ω–∫—Ü–∏—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è –ø–æ–ª–µ–π –¥–∞—Ç–∞—Å–µ—Ç–∞ –≤ alpaca prompt\n",
    "def formatting_prompts_func(examples):\n",
    "    instructions = examples[\"Instruction\"]\n",
    "    inputs       = examples[\"Input\"]\n",
    "    outputs      = examples[\"Response\"]\n",
    "    texts = []\n",
    "    for instruction, input, output in zip(instructions, inputs, outputs):\n",
    "        # Must add EOS_TOKEN, otherwise your generation will go on forever!\n",
    "        text = alpaca_prompt.format(instruction, input, output) + EOS_TOKEN\n",
    "        texts.append(text)\n",
    "    return { \"text\" : texts, }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1Q_jm9q_TYGT",
    "outputId": "8108be31-7102-4cf1-85b8-2c1d60c126fd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Input': '–ó–∞–ø—É—Å–∫ –∫–∞–Ω–∞–ª–∞ –æ Data Science',\n",
      " 'Instruction': 'Write a post on the following topic',\n",
      " 'Response': '–í—Å–µ–º –ø—Ä–∏–≤–µ—Ç!\\n'\n",
      "             '\\n'\n",
      "             '–†–µ—à–∏–ª –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–≤–æ–π –∫–∞–Ω–∞–ª. –ë—É–¥—É —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞—Ç—å –∑–¥–µ—Å—å –ø—Ä–æ —Å–≤–æ–π '\n",
      "             '–æ–ø—ã—Ç –≤ Data Science –∏ –ª–∞–π—Ñ—Ö–∞–∫–∏',\n",
      " 'text': 'Below is an instruction that describes a task, paired with an input '\n",
      "         'that provides further context. Write a response that appropriately '\n",
      "         'completes the request.\\n'\n",
      "         '\\n'\n",
      "         '### Instruction:\\n'\n",
      "         'Write a post on the following topic\\n'\n",
      "         '\\n'\n",
      "         '### Input:\\n'\n",
      "         '–ó–∞–ø—É—Å–∫ –∫–∞–Ω–∞–ª–∞ –æ Data Science\\n'\n",
      "         '\\n'\n",
      "         '### Response:\\n'\n",
      "         '–í—Å–µ–º –ø—Ä–∏–≤–µ—Ç!\\n'\n",
      "         '\\n'\n",
      "         '–†–µ—à–∏–ª –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–≤–æ–π –∫–∞–Ω–∞–ª. –ë—É–¥—É —Ä–∞—Å—Å–∫–∞–∑—ã–≤–∞—Ç—å –∑–¥–µ—Å—å –ø—Ä–æ —Å–≤–æ–π –æ–ø—ã—Ç –≤ '\n",
      "         'Data Science –∏ –ª–∞–π—Ñ—Ö–∞–∫–∏<|end_of_text|>'}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "from datasets import load_dataset\n",
    "\n",
    "# –°–∫–∞—á–∏–≤–∞–µ–º –ø–æ–¥–≥–æ—Ç–æ–≤–ª–µ–Ω–Ω—ã–π –¥–∞—Ç–∞—Å–µ—Ç —Å HuggingFace \n",
    "dataset = load_dataset(\"Ivanich/datafeeling_posts\", split = \"train\")\n",
    "\n",
    "# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –≤ alpaca_prompt —Å –ø–æ–º–æ—â—å—é –Ω–∞—à–µ–π —Ñ—É–Ω–∫—Ü–∏–∏ –∏ –º–µ—Ç–æ–¥–∞ map.\n",
    "dataset = dataset.map(formatting_prompts_func, batched = True,)\n",
    "\n",
    "pprint(dataset[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "–í–∏–¥–∏–º, —á—Ç–æ –≥–æ—Ç–æ–≤—ã–π –ø—Ä–æ–º–ø—Ç –¥–æ–±–∞–≤–∏–ª—Å—è –≤ –∫–æ–ª–æ–Ω–∫—É `text`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mDu8fiZZ63Sb"
   },
   "source": [
    "## –ü–µ—Ä–µ–¥ —Ç–µ–º –∫–∞–∫ –≤–æ—Ä–≤–∞—Ç—å—Å—è –≤ —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥\n",
    "–ü–æ—Å–º–æ—Ç—Ä–∏–º, –∫–∞–∫ –º–æ–¥–µ–ª—å —Å–ø—Ä–∞–≤–ª—è–µ—Ç—Å—è —Å –∑–∞–¥–∞—á–µ–π –¥–æ —Ñ–∞–π–Ω—Ç—é–Ω–∞?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9gqTLCuk5pmp",
    "outputId": "ba37d0b0-0a5c-4e53-c5d5-52cfd3b461f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|begin_of_text|>Below is an instruction that describes a task, paired with '\n",
      " 'an input that provides further context. Write a response that appropriately '\n",
      " 'completes the request.\\n'\n",
      " '\\n'\n",
      " '### Instruction:\\n'\n",
      " 'Write post about the following topic: \\n'\n",
      " '\\n'\n",
      " '### Input:\\n'\n",
      " '–ö–∞–∫ –∑–∞–ø—É—Å—Ç–∏—Ç—å gen ai —Å—Ç–∞—Ä—Ç–∞–ø\\n'\n",
      " '\\n'\n",
      " '### Response:\\n'\n",
      " '1. –ó–∞–ø—É—Å—Ç–∏—Ç—å –≥–µ–Ω–µ—Ç–∏—á–µ—Å–∫–∏–π –∞–ª–≥–æ—Ä–∏—Ç–º, –∫–æ—Ç–æ—Ä—ã–π –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –∏–¥–µ–∏ —Å—Ç–∞—Ä—Ç–∞–ø–æ–≤.\\n'\n",
      " '2. –í—ã–±—Ä–∞—Ç—å –∏–¥–µ–∏, –∫–æ—Ç–æ—Ä—ã–µ –∫–∞–∂—É—Ç—Å—è –≤–∞–º –Ω–∞–∏–±–æ–ª–µ–µ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã–º–∏.\\n'\n",
      " '3. –í—ã–ø–æ–ª–Ω–∏—Ç—å –∞–Ω–∞–ª–∏–∑ —Ä—ã–Ω–∫–∞ –∏ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ–≤ –¥–ª—è —ç—Ç–∏—Ö –∏–¥–µ–π.\\n'\n",
      " '4. –í—ã–ø–æ–ª–Ω–∏—Ç—å –º–∞—Ä–∫–µ—Ç–∏–Ω–≥–æ–≤—ã–π –∞–Ω–∞–ª–∏–∑ –∏ –∞–Ω–∞–ª–∏–∑ –ø–æ—Ç—Ä–µ–±–∏—Ç–µ–ª—å—Å–∫–æ–≥–æ –ø–æ–≤–µ–¥–µ–Ω–∏—è.\\n'\n",
      " '5. –í—ã–ø–æ–ª–Ω–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –±–∏–∑–Ω–µ—Å-–º–æ–¥–µ–ª–µ–π –∏ —Å—Ç—Ä–∞—Ç–µ–≥–∏–π.\\n'\n",
      " '6. –í—ã–ø–æ–ª–Ω–∏—Ç—å –∞–Ω–∞–ª–∏–∑ –∫–æ–Ω–∫—É—Ä–µ–Ω—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏ –∏ —Ä–∏—Å–∫–æ–≤.\\n'\n",
      " '7. –í—ã–ø–æ–ª–Ω–∏—Ç—å –∞–Ω–∞–ª–∏–∑ —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è –∏ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π.\\n'\n",
      " '8. –í—ã–ø']\n"
     ]
    }
   ],
   "source": [
    "FastLanguageModel.for_inference(model)\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    alpaca_prompt.format(\n",
    "        \"Write post about the following topic: \", # instruction\n",
    "        \"–ö–∞–∫ –∑–∞–ø—É—Å—Ç–∏—Ç—å gen ai —Å—Ç–∞—Ä—Ç–∞–ø\", # input\n",
    "        \"\", # output - leave this blank for generation!\n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 128, use_cache = True)\n",
    "pprint(tokenizer.batch_decode(outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "–í–∏–¥–∏–º, —á—Ç–æ –º–æ–¥–µ–ª—å –≤—ã–¥–∞—ë—Ç –∫–∞–∫–æ–π-—Ç–æ –ø–ª–∞–Ω —Å –ø—É–Ω–∫—Ç–∞–º–∏, –∏ —ç—Ç–æ –Ω–µ –æ—á–µ–Ω—å –ø–æ—Ö–æ–∂–µ –Ω–∞ –ø–æ—Å—Ç –¥–ª—è –∫–∞–Ω–∞–ª–∞."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idAEIeSQ3xdS"
   },
   "source": [
    "# <center id=\"part3\">   üöÄ –ó–∞–ø—É—Å–∫ —Ñ–∞–π–Ω—Ç—é–Ω–∞ / –î–æ–æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ \n",
    "–¢–µ–ø–µ—Ä—å –¥–∞–≤–∞–π—Ç–µ –≤–æ—Å–ø–æ–ª—å–∑—É–µ–º—Å—è `SFTTrainer` - supervised fine-tuning (–æ–±—É—á–µ–Ω–∏–µ –±–µ–∑ —É—á–∏—Ç–µ–ª—è) –æ—Ç `Huggingface TRL` . –¢–∞–∫ –Ω–∞–º –Ω–µ –ø—Ä–∏–¥–µ—Ç—Å—è –ø–∏—Å–∞—Ç—å —Å–≤–æ—é reward –º–æ–¥–µ–ª—å, –∫–æ—Ç–æ—Ä–æ–π –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –æ—Ü–µ–Ω–∏–≤–∞—Ç—å –æ—Ç–≤–µ—Ç Llama! <br>\n",
    "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—é –º–æ–∂–Ω–æ –Ω–∞–π—Ç–∏ –∑–¥–µ—Å—å: [–î–æ–∫—É–º–µ–Ω—Ç–∞—Ü–∏—è TRL SFT](https://huggingface.co/docs/trl/sft_trainer). <br>\n",
    "–¢–∞–∫–∂–µ `unsloth` –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç [`DPOTrainer`](https://huggingface.co/docs/trl/dpo_trainer) –æ—Ç TRL!\n",
    "\n",
    "–ú—ã –¥–µ–ª–∞–µ–º 60 —à–∞–≥–æ–≤, —á—Ç–æ–±—ã —É—Å–∫–æ—Ä–∏—Ç—å –ø—Ä–æ—Ü–µ—Å—Å, –Ω–æ –≤—ã –º–æ–∂–µ—Ç–µ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å `num_train_epochs=1` –¥–ª—è –ø–æ–ª–Ω–æ–≥–æ –∑–∞–ø—É—Å–∫–∞ –∏ –æ—Ç–∫–ª—é—á–∏—Ç—å `max_steps=None`. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center> –ö—Ä—É—Ç–∞—è –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –¥–ª—è —Å–∞–º—ã—Ö –ø—Ä–æ–¥–≤–∏–Ω—É—Ç—ã—Ö | Wandb\n",
    "\n",
    "–ü—Ä–∏ –∂–µ–ª–∞–Ω–∏–∏ –º–æ–∂–Ω–æ –ø–æ–¥–∫–ª—é—á–∏—Ç—å –±–∏–±–ª–∏–æ—Ç–µ–∫—É [Weights&Biases](https://wandb.ai/site) - –±–µ—Å–ø–ª–∞—Ç–Ω—ã–π —Ç—Ä–µ–∫–µ—Ä —ç–∫—Å–ø–µ—Ä–∏–º–µ–Ω—Ç–æ–≤. –ò —Ñ–∞–π–Ω—Ç—é–Ω–Ω–∏—Ç—å –ø–æ –≤–∑—Ä–æ—Å–ª–æ–º—É."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "\n",
    "# wb_token = 'WANDB_API_KEY' # –∫–ª—é—á c —Å–∞–π—Ç–∞ Weights & Biases https://wandb.ai/site\n",
    "# wandb.login(key=wb_token)\n",
    "# –¥–∞–ª–µ–µ —Ä–∞—Å–∫–æ–º–º–µ–Ω—Ç–∏—Ä—É–π—Ç–µ –ø–∞—Ä–∞–º–µ—Ç—Ä record_to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "95_Nn-89DhsL",
    "outputId": "476f105b-b374-4861-eec5-88b0f3c859a6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "max_steps is given, it will override any value given in num_train_epochs\n"
     ]
    }
   ],
   "source": [
    "from trl import SFTTrainer\n",
    "from transformers import TrainingArguments\n",
    "from unsloth import is_bfloat16_supported\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model = model,\n",
    "    tokenizer = tokenizer,\n",
    "    train_dataset = dataset,\n",
    "    dataset_text_field = \"text\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    dataset_num_proc = 2,\n",
    "    packing = False, # Can make training 5x faster for short sequences.\n",
    "    args = TrainingArguments(\n",
    "        per_device_train_batch_size = 4,\n",
    "        gradient_accumulation_steps = 2,\n",
    "        warmup_steps = 10,\n",
    "        #num_train_epochs = 1, # Set this for 1 full training run.\n",
    "        max_steps = 60,\n",
    "        learning_rate = 2e-4,\n",
    "        fp16 = not is_bfloat16_supported(),\n",
    "        bf16 = is_bfloat16_supported(),\n",
    "        logging_steps = 1,\n",
    "        optim = \"adamw_8bit\",\n",
    "        weight_decay = 0.01,\n",
    "        lr_scheduler_type = \"linear\",\n",
    "        seed = 3407,\n",
    "        output_dir = \"outputs\",\n",
    "        # report_to=\"wandb\", # –ï—Å–ª–∏ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç–µ Weights & Biases\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ejIt2xSNKKp",
    "outputId": "c4b07c62-3201-4a90-f024-560a86785d23"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU = Tesla T4. Max memory = 14.748 GB.\n",
      "12.742 GB of memory reserved.\n"
     ]
    }
   ],
   "source": [
    "#@title Show current memory stats\n",
    "gpu_stats = torch.cuda.get_device_properties(0)\n",
    "start_gpu_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "max_memory = round(gpu_stats.total_memory / 1024 / 1024 / 1024, 3)\n",
    "\n",
    "print(f\"GPU = {gpu_stats.name}. Max memory = {max_memory} GB.\")\n",
    "print(f\"{start_gpu_memory} GB of memory reserved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "yqxqAZ7KJ4oL",
    "outputId": "bbe9d498-00da-414d-99ad-14388acf1014"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "==((====))==  Unsloth - 2x faster free finetuning | Num GPUs = 1\n",
      "   \\\\   /|    Num examples = 587 | Num Epochs = 4\n",
      "O^O/ \\_/ \\    Batch size per device = 8 | Gradient Accumulation steps = 4\n",
      "\\        /    Total batch size = 32 | Total steps = 60\n",
      " \"-____-\"     Number of trainable parameters = 41,943,040\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='60' max='60' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [60/60 43:35, Epoch 3/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>2.236400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.247700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>2.328900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2.165200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>2.294000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>2.186900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>2.269100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>2.214700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>2.289900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>2.298600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>2.244600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>2.201800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>2.153100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>2.188300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>2.166900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>2.182000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>2.188200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>2.098000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>2.084500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>2.096200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>2.201400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>2.091800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>23</td>\n",
       "      <td>2.053300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>24</td>\n",
       "      <td>2.117500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25</td>\n",
       "      <td>2.018800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>26</td>\n",
       "      <td>2.011700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>27</td>\n",
       "      <td>1.953300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>28</td>\n",
       "      <td>1.964100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>2.048200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>1.907600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>31</td>\n",
       "      <td>2.030600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>32</td>\n",
       "      <td>2.014700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>33</td>\n",
       "      <td>1.982400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>34</td>\n",
       "      <td>1.982400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>35</td>\n",
       "      <td>1.898200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>36</td>\n",
       "      <td>2.025500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>37</td>\n",
       "      <td>1.779900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>38</td>\n",
       "      <td>2.007600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39</td>\n",
       "      <td>1.968800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>40</td>\n",
       "      <td>1.961200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>41</td>\n",
       "      <td>1.911900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>42</td>\n",
       "      <td>1.888400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>43</td>\n",
       "      <td>1.826900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>44</td>\n",
       "      <td>1.803100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>1.816400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>46</td>\n",
       "      <td>1.819600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>47</td>\n",
       "      <td>1.691800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>48</td>\n",
       "      <td>1.928200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>49</td>\n",
       "      <td>1.881500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>1.897900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>51</td>\n",
       "      <td>1.940600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>52</td>\n",
       "      <td>1.860200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>53</td>\n",
       "      <td>1.859400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>54</td>\n",
       "      <td>1.853800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>55</td>\n",
       "      <td>1.901000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>56</td>\n",
       "      <td>1.895100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>57</td>\n",
       "      <td>1.795600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>58</td>\n",
       "      <td>1.882400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>59</td>\n",
       "      <td>1.795100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>1.654000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# –ó–∞–ø—É—Å–∫–∞–µ–º —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫—É!\n",
    "trainer_stats = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pCqnaKmlO1U9",
    "outputId": "7e351717-6f83-4794-dff1-633468bc3b3f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2669.216 seconds used for training.\n",
      "44.49 minutes used for training.\n",
      "Peak reserved memory = 12.742 GB.\n",
      "Peak reserved memory for training = 0.0 GB.\n",
      "Peak reserved memory % of max memory = 86.398 %.\n",
      "Peak reserved memory for training % of max memory = 0.0 %.\n"
     ]
    }
   ],
   "source": [
    "#@title Show final memory and time stats\n",
    "used_memory = round(torch.cuda.max_memory_reserved() / 1024 / 1024 / 1024, 3)\n",
    "used_memory_for_lora = round(used_memory - start_gpu_memory, 3)\n",
    "used_percentage = round(used_memory         /max_memory*100, 3)\n",
    "lora_percentage = round(used_memory_for_lora/max_memory*100, 3)\n",
    "print(f\"{trainer_stats.metrics['train_runtime']} seconds used for training.\")\n",
    "print(f\"{round(trainer_stats.metrics['train_runtime']/60, 2)} minutes used for training.\")\n",
    "print(f\"Peak reserved memory = {used_memory} GB.\")\n",
    "print(f\"Peak reserved memory for training = {used_memory_for_lora} GB.\")\n",
    "print(f\"Peak reserved memory % of max memory = {used_percentage} %.\")\n",
    "print(f\"Peak reserved memory for training % of max memory = {lora_percentage} %.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ekOmTR1hSNcr"
   },
   "source": [
    "# <center id=\"part4\">  –ò–Ω—Ñ–µ—Ä–µ–Ω—Å üí¨\n",
    "–î–∞–≤–∞–π—Ç–µ –∑–∞–ø—É—Å—Ç–∏–º –º–æ–¥–µ–ª—å! –ú–æ–∂–µ—Ç–µ –∏–∑–º–µ–Ω–∏—Ç—å –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –∏ –≤–≤–æ–¥, Response –æ—Å—Ç–∞–≤–∏–º –ø—É—Å—Ç—ã–º!\n",
    "\n",
    "–ü–æ–ø—Ä–æ–±–æ–≤–∞—Ç—å –≤–¥–≤–æ–µ —É—Å–∫–æ—Ä–∏—Ç—å –∏–Ω—Ñ–µ—Ä–µ–Ω—Å –º–æ–∂–Ω–æ –≤ Colab –¥–ª—è **Llama-3.1 8b Instruct** [–∑–¥–µ—Å—å](https://colab.research.google.com/drive/1T-YBVfnphoVc8E2E854qF3jdia2Ll2W2?usp=sharing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kR3gIAX-SM2q",
    "outputId": "ec9e915d-ddd7-4249-d135-1676b26f6c69",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<|begin_of_text|>Below is an instruction that describes a task, paired with '\n",
      " 'an input that provides further context. Write a response that appropriately '\n",
      " 'completes the request.\\n'\n",
      " '\\n'\n",
      " '### Instruction:\\n'\n",
      " 'Write post about the following topic: \\n'\n",
      " '\\n'\n",
      " '### Input:\\n'\n",
      " '–∫–∞–∫ –∑–∞–ø—É—Å—Ç–∏—Ç—å gen ai —Å—Ç–∞—Ä—Ç–∞–ø\\n'\n",
      " '\\n'\n",
      " '### Response:\\n'\n",
      " 'üé§ –°–µ–≥–æ–¥–Ω—è —É –º–µ–Ω—è –±—ã–ª –∏–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π –æ–ø—ã—Ç. \\n'\n",
      " '\\n'\n",
      " 'üîù –í—Å—Ç—Ä–µ—Ç–∏–ª—Å—è —Å 2-–º—è —Ä–µ–±—è—Ç–∞–º–∏, –∫–æ—Ç–æ—Ä—ã–µ —Ö–æ—Ç—è—Ç –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–≤–æ–π gen ai —Å—Ç–∞—Ä—Ç–∞–ø. \\n'\n",
      " '\\n'\n",
      " 'üèÜ –í —Ü–µ–ª–æ–º, –≤—Å–µ –±—ã–ª–æ –∫–ª–∞—Å—Å–Ω–æ. –£ –Ω–∏—Ö –∫—Ä—É—Ç–æ–π –æ–ø—ã—Ç, —Ö–æ—Ä–æ—à–∏–π —Ç–∏–º–±–∏–ª–¥–∏–Ω–≥ –∏ '\n",
      " '–∏–Ω—Ç–µ—Ä–µ—Å–Ω–∞—è –∑–∞–¥—É–º–∫–∞. \\n'\n",
      " '\\n'\n",
      " 'ü§î –û–¥–Ω–∞–∫–æ, —è –≤—Å–µ –∂–µ –ø–æ—Å–æ–≤–µ—Ç–æ–≤–∞–ª –∏–º –Ω–µ –∑–∞–ø—É—Å–∫–∞—Ç—å —Å—Ç–∞—Ä—Ç–∞–ø, –∞ –ø—Ä–æ—Å—Ç–æ —Å–∫–∏–Ω—É—Ç—å '\n",
      " '—Å–≤–æ—é –∏–¥–µ—é –≤ –Ω–∞—à—É ML –ª–æ—Ç–µ—Ä–µ—é. \\n'\n",
      " '\\n'\n",
      " 'ü§î –ü–æ–Ω—è—Ç–Ω–æ, —á—Ç–æ —ç—Ç–æ –Ω–µ —Å–æ–≤—Å–µ–º']\n"
     ]
    }
   ],
   "source": [
    "# alpaca_prompt = Copied from above\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    alpaca_prompt.format(\n",
    "        \"Write post about the following topic: \", # instruction\n",
    "        \"–∫–∞–∫ –∑–∞–ø—É—Å—Ç–∏—Ç—å gen ai —Å—Ç–∞—Ä—Ç–∞–ø\", # input\n",
    "        \"\", # output - leave this blank for generation!\n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 128, use_cache = True)\n",
    "pprint(tokenizer.batch_decode(outputs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "‚úÖ –ü–æ—Å–ª–µ —Ñ–∞–π–Ω—Ç—é–Ω–∞ –º–æ–¥–µ–ª—å –ø–æ —Ç–æ–º—É –∂–µ –∑–∞–ø—Ä–æ—Å—É –ø–∏—à–µ—Ç –ø–æ—Å—Ç, –∏ —è–≤–Ω–æ —É–≥–∞–¥—ã–≤–∞–µ—Ç—Å—è —Å—Ç–∏–ª—å –ø–æ—Å—Ç–æ–≤ –∫–∞–Ω–∞–ª–∞ [Datafeeling](https://t.me/datafeeling)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CrSvZObor0lY"
   },
   "source": [
    " **–ó–∞–ø—É—Å–∫ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –≤ —Ä–µ–∂–∏–º–µ —Å—Ç—Ä–∏–º–∏–Ω–≥–∞:** –í—ã —Ç–∞–∫–∂–µ –º–æ–∂–µ—Ç–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å `TextStreamer` –¥–ª—è –Ω–µ–ø—Ä–µ—Ä—ã–≤–Ω–æ–≥–æ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞, —á—Ç–æ–±—ã –≤—ã –º–æ–≥–ª–∏ –≤–∏–¥–µ—Ç—å –≥–µ–Ω–µ—Ä–∞—Ü–∏—é —Ç–æ–∫–µ–Ω –∑–∞ —Ç–æ–∫–µ–Ω–æ–º!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e2pEuRb1r2Vg",
    "outputId": "b289b319-ddff-430b-ff0e-d29a403ae59e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\n",
      "\n",
      "### Instruction:\n",
      "Write post about the following topic: \n",
      "\n",
      "### Input:\n",
      "–ö–∞–∫ —Å—Ç–∞—Ç—å kaggle master\n",
      "\n",
      "### Response:\n",
      "üèÜ –ö–∞–∫ —Å—Ç–∞—Ç—å kaggle master\n",
      "\n",
      "ü§î –ù–∞ Kaggle —Å–µ–π—á–∞—Å –º–Ω–æ–≥–æ –º—ç—Ç—á–µ–π, –≤ –∫–æ—Ç–æ—Ä—ã—Ö –º–æ–∂–Ω–æ —Å–∫–∏–Ω—É—Ç—å –ª–∏–¥–µ—Ä–±–æ—Ä–¥. –ò —ç—Ç–æ –ø—Ä–µ–∫—Ä–∞—Å–Ω–æ, –Ω–æ –≤–æ—Ç —Ç–æ–ª—å–∫–æ –Ω–µ –≤—Å–µ —Ç–∞–∫ –ø—Ä–æ—Å—Ç–æ. \n",
      "\n",
      "ü§´ –ï—Å–ª–∏ —Ç—ã —Ö–æ—á–µ—à—å –¥–æ–±–∏—Ç—å—Å—è —É—Å–ø–µ—Ö–∞, —Ç–æ –ø—Ä–∏–¥–µ—Ç—Å—è –º–Ω–æ–≥–æ –ø–æ—Ç—Ä—É–¥–∏—Ç—å—Å—è. –í –ø—Ä–æ—Ç–∏–≤–Ω–æ–º —Å–ª—É—á–∞–µ —Ç—ã –ø—Ä–æ—Å—Ç–æ –Ω–µ –¥–æ–±—å–µ—à—å—Å—è —É—Å–ø–µ—Ö–∞. –ò —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ, –Ω–µ —Å—É–¥–∏—Ç–µ. \n",
      "\n",
      "ü§î –ü–æ—ç—Ç–æ–º—É, –µ—Å–ª–∏ —Ç—ã —Ö–æ—á–µ—à—å –¥–æ–±–∏—Ç—å—Å—è —É—Å–ø–µ—Ö–∞, —Ç–æ –ø—Ä–∏–¥–µ—Ç—Å—è –º–Ω–æ–≥–æ –ø–æ—Ç—Ä—É–¥–∏—Ç—å—Å—è. –ò —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–æ, –Ω–µ —Å—É–¥–∏—Ç–µ. \n",
      "\n",
      "ÔøΩ\n"
     ]
    }
   ],
   "source": [
    "from transformers import TextStreamer\n",
    "\n",
    "FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    alpaca_prompt.format(\n",
    "        \"Write post about the following topic: \", # instruction\n",
    "        \"–ö–∞–∫ —Å—Ç–∞—Ç—å kaggle master\", # input\n",
    "        \"\", # output - leave this blank for generation!\n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "\n",
    "text_streamer = TextStreamer(tokenizer)\n",
    "_ = model.generate(**inputs, streamer = text_streamer, max_new_tokens = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uMuVrWbjAzhc"
   },
   "source": [
    "### <center> –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ, –∑–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–Ω—Ç—é–Ω–µ–Ω–Ω—ã—Ö –º–æ–¥–µ–ª–µ–π\n",
    "–ß—Ç–æ–±—ã —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –æ–∫–æ–Ω—á–∞—Ç–µ–ª—å–Ω—É—é –º–æ–¥–µ–ª—å –≤ –∫–∞—á–µ—Å—Ç–≤–µ –∞–¥–∞–ø—Ç–µ—Ä–æ–≤ `LoRA`, –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ:\n",
    "* –ª–∏–±–æ `push_to_hub` –æ—Ç **Huggingface** –¥–ª—è –æ–Ω–ª–∞–π–Ω-—Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è \n",
    "* –ª–∏–±–æ `save_pretrained` –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–æ–≥–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è\n",
    "\n",
    "**–í–∞–∂–Ω–æ:** —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è –¢–û–õ–¨–ö–û –∞–¥–∞–ø—Ç–µ—Ä `LoRA`, –∞ –Ω–µ –ø–æ–ª–Ω–∞—è –º–æ–¥–µ–ª—å. –ö–∞–∫ —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ 16-–±–∏—Ç–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ –∏–ª–∏ `GGUF` —Å–º–æ—Ç—Ä–∏—Ç–µ –≤ [—ç—Ç–æ–º –Ω–æ—É—Ç–±—É–∫–µ](https://colab.research.google.com/drive/1Ys44kVvmeZtnICzWz0xgpRnrIOjZAuxp?usp=sharing)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Pt-g2YquOa8",
    "outputId": "5ff05c43-7bb8-4c34-b3c9-35102ba254f5"
   },
   "outputs": [],
   "source": [
    "from getpass import getpass\n",
    "\n",
    "hf_token = getpass(prompt=\"–í–≤–µ–¥–∏—Ç–µ –≤–∞—à HuggingFaceHub API –∫–ª—é—á\")\n",
    "hf_username = 'Ivanich' # –í–≤–æ–¥–∏–º —Å–≤–æ–π username –Ω–∞ HugginFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 130,
     "referenced_widgets": [
      "497302a6acc84773a84ff23cd36da214",
      "b62cf033432f40e0a9ee259515167b51",
      "22eed99a28c74a80a42f95cc2529913b",
      "1f07aa6d2b744092ac1b2f13352b3909",
      "7a7468b6571c4b818f706b13e37345b5",
      "d2117400d4744ac498d1582a3336f905",
      "36e5a40703714c76ba41451af838a1fe",
      "0374d3f515e640ea80e11cb8cffdbf7d",
      "e08504a1906e41bf8cfe2e7d231e0f2f",
      "1417bf853c6241038d6d01fae7183091",
      "9d78a73117ff4b59b6f6499b7f978d14",
      "297389dcbf3040f19fb6773f776f3f2e",
      "1a8353acfc6e4a77b5e754ec3a9d164e",
      "a6784a8092dd4652bb19a142b05986b1",
      "74d5c798f06346e9bd1cf96bf72669ff",
      "d937f93cbe12423d9198d740769eaaad",
      "3d7de1da6dc5424bb29a8510b1cfc549",
      "d9f595f07ea14377ad4f2af81b3dc236",
      "3267638f39f34833955764925bc59ad9",
      "7a23197e84e449a6b77b893f4bcc81fb",
      "6747454af34a467690d783bae764fbfa",
      "d6ef70581b8841d4b7455f1074373478",
      "177ec807de33414281f03b5790021dc8",
      "a1242cc96bf9450abbbc00593bc7c8a8",
      "906abe2734de4a7bbceb71fefb265ae8",
      "de7e5ca6727c4c0d99522d35981a4ad2",
      "7ca294a7b4aa40668f8ea154f744a4b4",
      "d27389522e9c437695f0e93a0ecf1f09",
      "16b0f13d883d48809d4703704f43204c",
      "2c90127799134934b6eb68325838a8a8",
      "c0a6e820a2eb41dc9c6244f614272ef5",
      "a4a6ed211ca44d509cb82311c27caba3",
      "c7a2e8fad27e4fa2b9c80a970002d6bd"
     ]
    },
    "id": "upcOlWe7A1vc",
    "outputId": "64f23760-f101-4ef6-e7f8-384eec50db9d"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "497302a6acc84773a84ff23cd36da214",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "README.md:   0%|          | 0.00/588 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "297389dcbf3040f19fb6773f776f3f2e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "177ec807de33414281f03b5790021dc8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "adapter_model.safetensors:   0%|          | 0.00/168M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to https://huggingface.co/Ivanich/datafeeling_model\n"
     ]
    }
   ],
   "source": [
    "model.save_pretrained(\"datafeeling_model\") # Local saving\n",
    "tokenizer.save_pretrained(\"datafeeling_model\")\n",
    "\n",
    "model.push_to_hub(f\"{hf_username}/datafeeling_model\", token = hf_token) # Online saving\n",
    "tokenizer.push_to_hub(f\"{hf_username}/datafeeling_model\", token = hf_token) # Online saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "–ï—Å–ª–∏ –ø–µ—Ä–µ–π—Ç–∏ –ø–æ —Å—Å—ã–ª–∫–µ, –∫–æ—Ç–æ—Ä—É—é –≤—ã–¥–∞–µ—Ç HF –ø–æ—Å–ª–µ –∑–∞–≥—Ä—É–∑–∫–∏ –Ω–∞ —Ö–∞–± - —É–≤–∏–¥–∏–º, —á—Ç–æ —Å–æ—Ö—Ä–∞–Ω–∏–ª–∞—Å—å –Ω–µ –≤—Å—è –º–æ–¥–µ–ª—å, –∞ —Ç–æ–ª—å–∫–æ –≤–µ—Å–∞ –∞–¥–∞–ø—Ç–µ—Ä–∞ LoRA (168 Mb). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AEEcJ4qfC7Lp"
   },
   "source": [
    "Now if you want to load the LoRA adapters we just saved for inference, set `False` to `True`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MKX_XKs_BNZR",
    "outputId": "7431de93-bc80-48b7-9491-1f3ce12615fd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<|begin_of_text|>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.\\n\\n### Instruction:\\nWrite post about the following topic\\n\\n### Input:\\n–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–æ–ª–µ–π –≤ —Å—Ç–∞—Ä—Ç–∞–ø–µ\\n\\n### Response:\\n–Ø –¥—É–º–∞—é, —á—Ç–æ —ç—Ç–æ –æ—á–µ–Ω—å –≤–∞–∂–Ω—ã–π –≤–æ–ø—Ä–æ—Å: –∫–∞–∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è—Ç—å –¥–æ–ª–∏ –≤ —Å—Ç–∞—Ä—Ç–∞–ø–µ? –ò, —á—Ç–æ –µ—â–µ –≤–∞–∂–Ω–µ–µ, –∫–∞–∫ —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è—Ç—å –¥–æ–ª–∏ –≤ —Å—Ç–∞—Ä—Ç–∞–ø–µ, –∫–æ–≥–¥–∞ –≤—ã –µ—â–µ –Ω–µ –∑–Ω–∞–µ—Ç–µ, –∫–∞–∫–∏–º –±—É–¥–µ—Ç —Å—Ç–∞—Ä—Ç–∞–ø?  –û—á–µ–Ω—å –º–Ω–æ–≥–æ –ª—é–¥–µ–π –≤ —Å—Ç–∞—Ä—Ç–∞–ø–∞—Ö, –∫–æ—Ç–æ—Ä—ã–µ –¥–µ–ª–∞—é—Ç —ç—Ç–æ –ø–æ-—Å—Ç–∞—Ä–æ–º—É, —Ç–æ –µ—Å—Ç—å, —Ä–∞—Å–ø—Ä–µ–¥–µ–ª—è—é—Ç –¥–æ–ª–∏ –ø–æ —Å—Ç–∞—Ç—É—Å—É: founder, cofounder, employee, contractor, investor, etc. –≠—Ç–æ –Ω–µ —Ç–∞–∫ –ø–ª–æ—Ö–æ, –Ω–æ, —Å –¥—Ä—É–≥–æ–π —Å—Ç–æ—Ä–æ–Ω—ã, —è –Ω–µ –∑–Ω–∞—é –Ω–∏ –æ–¥–Ω–æ–≥–æ —Å—Ç–∞—Ä—Ç–∞–ø–∞, –∫–æ—Ç–æ—Ä—ã–π –±—ã –±—ã–ª —É—Å–ø–µ—à']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if False:\n",
    "    from unsloth import FastLanguageModel\n",
    "    model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "        model_name = \"datafeeling_model\", # YOUR MODEL YOU USED FOR TRAINING\n",
    "        max_seq_length = max_seq_length,\n",
    "        dtype = dtype,\n",
    "        load_in_4bit = load_in_4bit,\n",
    "    )\n",
    "    FastLanguageModel.for_inference(model) # Enable native 2x faster inference\n",
    "\n",
    "# alpaca_prompt = You MUST copy from above!\n",
    "\n",
    "inputs = tokenizer(\n",
    "[\n",
    "    alpaca_prompt.format(\n",
    "        \"Write post about the following topic\", # instruction\n",
    "        \"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–æ–ª–µ–π –≤ —Å—Ç–∞—Ä—Ç–∞–ø–µ\", # input\n",
    "        \"\", # output - leave this blank for generation!\n",
    "    )\n",
    "], return_tensors = \"pt\").to(\"cuda\")\n",
    "\n",
    "outputs = model.generate(**inputs, max_new_tokens = 128, use_cache = True)\n",
    "tokenizer.batch_decode(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚úÖ –û—Ç–ª–∏—á–Ω–æ, –≤–∏–¥–∏–º, —á—Ç–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ–ª—É—á–∏–ª—Å—è –ø–æ—Ö–æ–∂–∏–º –Ω–∞ –ø—Ä–∞–≤–¥—É"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center id=\"part6\"> –ê —á—Ç–æ –µ—â—ë –∏–∑ –ø–æ–ª–µ–∑–Ω–æ–≥–æ?\n",
    "\n",
    "<div class=\"alert alert-success\">\n",
    "    \n",
    "* [RAFT](https://arxiv.org/abs/2403.10131) - RAG + Fine Tuning - —Ñ–∞–π–Ω—Ç—é–Ω—è—Ç –º–æ–¥–µ–ª—å, —á—Ç–æ–±—ã –æ—Ç–±–∏—Ä–∞—Ç—å –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è RAG\n",
    "* [Finetuning ChatGPT](https://platform.openai.com/docs/guides/fine-tuning) - OpenAI –∏ Anthropic –æ–±—ä—è–≤–∏–ª–∏, —á—Ç–æ –º–æ–∂–Ω–æ –±—É–¥–µ—Ç —Ñ–∞–π–Ω—Ç—é–Ω–∏—Ç—å –∏—Ö –º–æ–¥–µ–ª–∏ –Ω–∞ —Å–≤–æ–∏—Ö –¥–∞–Ω–Ω—ã—Ö, –∞ –ø–æ—Ç–æ–º –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —ç—Ç–∏ –≤–µ—Ä—Å–∏–∏ –º–æ–¥–µ–ª–µ–π –ø–æ API (–ø–ª–∞—Ç–Ω–æ).\n",
    "* [–î–∞—Ç–∞—Å–µ—Ç](https://huggingface.co/datasets/Ivanich/datafeeling_posts) —Å –ø–æ—Å—Ç–∞–º–∏ –∫–∞–Ω–∞–ª–∞ Datafeeling, —Å–æ–±—Ä–∞–Ω–Ω—ã–π –≤ —ç—Ç–æ–º [–Ω–æ—É—Ç–±—É–∫–µ](https://github.com/a-milenkin/LLM_practical_course/blob/main/notebooks/M5_2_Dataset_prepare.ipynb).\n",
    "* –ü—Ä–∏–º–µ—Ä —Ñ–∞–π–Ω—Ç—é–Ω–∏–Ω–≥–∞ –Ω–∞ –≥–æ—Ç–æ–≤–æ–º –¥–∞—Ç–∞—Å–µ—Ç–µ —Å HuggingFace c –º–µ–¥–∏—Ü–∏–Ω—Å–∫–∏–º–∏ –¥–∞–Ω–Ω—ã–º–∏. –û—Ñ–æ—Ä–º–∏–ª–∏ –≤ –≤–∏–¥–µ [—Å—Ç–∞—Ç—å–∏ –Ω–∞ –•–∞–±—Ä](https://habr.com/ru/articles/832984/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center id=\"part7\"> üß∏ –í—ã–≤–æ–¥—ã –∏ –∑–∞–∫–ª—é—á–µ–Ω–∏—è ‚úÖ\n",
    "\n",
    "**–ü–ª—é—Å—ã FT:**\n",
    "* –ë–æ–ª–µ–µ –∫–æ–Ω—Å–∏—Å—Ç–µ–Ω—Ç–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≥–µ–Ω—Ä–∞—Ü–∏–∏ (–Ω–∞–ø—Ä–∏–º–µ—Ä, –º–æ–∂–Ω–æ –ø–µ—Ä–µ–¥–∞—Ç—å —Å—Ç–∏–ª–∏—Å—Ç–∏–∫—É –∞–≤—Ç–æ—Ä–∞)\n",
    "* –£–º–µ–Ω—å—à–µ–Ω–∏–µ –≥–∞–ª–ª—é—Ü–∏–Ω–∞—Ü–∏–π (—Å–ª–µ–¥–æ–≤–∞–Ω–∏–µ –Ω–æ–≤—ã–º –¥–æ–º–µ–Ω–Ω—ã–º –∑–Ω–∞–Ω–∏—è–º–∏)\n",
    "* –ú–æ–∂–Ω–æ –Ω–∞—Ç—Ä–µ–Ω–∏—Ä–æ–≤–∞—Ç—å –ø–æ–¥ —Å–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–π —é–∑–∫–µ–π—Å\n",
    "* –ù–µ –∑–∞–±—ã–≤–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ (—Ö—Ä–∞–Ω—è—Ç—Å—è –≤ –≤–µ—Å–∞—Ö –º–æ–¥–µ–ª–∏)\n",
    "* –ú–æ–∂–Ω–æ –ø–µ—Ä–µ–¥–∞—Ç—å –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö, —á–µ–º –≤ RAG (—Ç.–∫. –Ω–µ—Ç –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–π –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–≥–æ –æ–∫–Ω–∞)\n",
    "* –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –Ω–µ–±–æ–ª—å—à–∏–µ –º–æ–¥–µ–ª–∏ - –º–µ–Ω—å—à–µ –∑–∞—Ç—Ä–∞—Ç –Ω–∞ –¥–∞–ª—å–Ω–µ–π—à–µ–µ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ\n",
    "* –ü—Ä–∏–≤–∞—Ç–Ω–æ—Å—Ç—å - –¥–∞–Ω–Ω—ã–µ –Ω–µ –ø–µ—Ä–µ–¥–∞—é—Ç—Å—è –æ—Ç–∫—Ä—ã—Ç–æ –≤ –ø—Ä–æ–º–ø—Ç–µ, –∞ \"–∑–∞—à–∏—Ç—ã\" –≤ –≤–µ—Å–∞—Ö (–º–µ–Ω—å—à–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–µ–π –¥–ª—è –ø—Ä–æ–º–ø—Ç-—Ö–∞–∫–∏–Ω–≥–∞)\n",
    "* –í—ã—à–µ —Å–∫–æ—Ä–æ—Å—Ç—å –∏–Ω—Ñ–µ—Ä–µ–Ω—Å–∞ –ø–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—é —Å RAG (—Ç.–∫. –Ω–µ –Ω—É–∂–Ω–æ –¥–µ–ª–∞—Ç—å —Å–µ–º–∞–Ω—Ç–∏—á–µ—Å–∫–∏–π –ø–æ–∏—Å–∫ –ø–æ –±–∞–∑–µ –∏ –∫–æ—Ä–æ—á–µ –ø—Ä–æ–º–ø—Ç, –±—ã—Å—Ç—Ä–µ–µ –Ω–∞—á–∏–Ω–∞–µ—Ç—Å—è –≥–µ–Ω–µ—Ä–∞—Ü–∏—è)\n",
    "\n",
    "**–ú–∏–Ω—É—Å—ã FT:**\n",
    "* –ù—É–∂–Ω–æ —Å–æ–±—Ä–∞—Ç—å –≥–æ—Ä–∞–∑–¥–æ –±–æ–ª—å—à–µ –¥–∞–Ω–Ω—ã—Ö (—Å–∞–º–∞—è —Ç—Ä—É–¥–æ–µ–º–∫–∞—è –∏ –≤–∞–∂–Ω–∞—è —á–∞—Å—Ç—å)\n",
    "* –ü–æ–≤—ã—à–µ–Ω–Ω—ã–π –ø–æ—Ä–æ–≥ –≤—Ö–æ–¥–∞ - –Ω—É–∂–Ω—ã –±–æ–ª–µ–µ –≥–ª—É–±–æ–∫–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –∑–Ω–∞–Ω–∏—è\n",
    "* –ù—É–∂–Ω–æ –±–æ–ª—å—à–µ —Ä–µ—Å—É—Ä—Å–æ–≤ –∏ –≤—Ä–µ–º–µ–Ω–∏ –Ω–∞ —Å—Ç–∞—Ä—Ç–µ\n",
    "* –ù–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç—å –ø–µ—Ä–µ—É—á–∏–≤–∞—Ç—å –ø—Ä–∏ –≤—ã—Ö–æ–¥–µ –Ω–æ–≤—ã—Ö –≤–µ—Ä—Å–∏–π –º–æ–¥–µ–ª–∏\n",
    "* –ò–Ω–æ–≥–¥–∞ –≤—Å–µ —Ä–∞–≤–Ω–æ –ø—Ä–∏–¥–µ—Ç—Å—è –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å RAG –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ –Ω–æ–≤–æ–π —á–∞—Å—Ç–æ –∏–∑–º–µ–Ω—è—é—â–µ–π—Å—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "cv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0374d3f515e640ea80e11cb8cffdbf7d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1417bf853c6241038d6d01fae7183091": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "16b0f13d883d48809d4703704f43204c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "177ec807de33414281f03b5790021dc8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a1242cc96bf9450abbbc00593bc7c8a8",
       "IPY_MODEL_906abe2734de4a7bbceb71fefb265ae8",
       "IPY_MODEL_de7e5ca6727c4c0d99522d35981a4ad2"
      ],
      "layout": "IPY_MODEL_7ca294a7b4aa40668f8ea154f744a4b4"
     }
    },
    "1a8353acfc6e4a77b5e754ec3a9d164e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3d7de1da6dc5424bb29a8510b1cfc549",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_d9f595f07ea14377ad4f2af81b3dc236",
      "value": "100%"
     }
    },
    "1f07aa6d2b744092ac1b2f13352b3909": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_1417bf853c6241038d6d01fae7183091",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_9d78a73117ff4b59b6f6499b7f978d14",
      "value": "‚Äá588/588‚Äá[00:00&lt;00:00,‚Äá33.5kB/s]"
     }
    },
    "22eed99a28c74a80a42f95cc2529913b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0374d3f515e640ea80e11cb8cffdbf7d",
      "max": 588,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_e08504a1906e41bf8cfe2e7d231e0f2f",
      "value": 588
     }
    },
    "297389dcbf3040f19fb6773f776f3f2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_1a8353acfc6e4a77b5e754ec3a9d164e",
       "IPY_MODEL_a6784a8092dd4652bb19a142b05986b1",
       "IPY_MODEL_74d5c798f06346e9bd1cf96bf72669ff"
      ],
      "layout": "IPY_MODEL_d937f93cbe12423d9198d740769eaaad"
     }
    },
    "2c90127799134934b6eb68325838a8a8": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3267638f39f34833955764925bc59ad9": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "36e5a40703714c76ba41451af838a1fe": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "3d7de1da6dc5424bb29a8510b1cfc549": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "497302a6acc84773a84ff23cd36da214": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b62cf033432f40e0a9ee259515167b51",
       "IPY_MODEL_22eed99a28c74a80a42f95cc2529913b",
       "IPY_MODEL_1f07aa6d2b744092ac1b2f13352b3909"
      ],
      "layout": "IPY_MODEL_7a7468b6571c4b818f706b13e37345b5"
     }
    },
    "6747454af34a467690d783bae764fbfa": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "74d5c798f06346e9bd1cf96bf72669ff": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6747454af34a467690d783bae764fbfa",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_d6ef70581b8841d4b7455f1074373478",
      "value": "‚Äá1/1‚Äá[00:02&lt;00:00,‚Äá‚Äá2.84s/it]"
     }
    },
    "7a23197e84e449a6b77b893f4bcc81fb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "7a7468b6571c4b818f706b13e37345b5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7ca294a7b4aa40668f8ea154f744a4b4": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "906abe2734de4a7bbceb71fefb265ae8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_2c90127799134934b6eb68325838a8a8",
      "max": 167832240,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c0a6e820a2eb41dc9c6244f614272ef5",
      "value": 167832240
     }
    },
    "9d78a73117ff4b59b6f6499b7f978d14": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "a1242cc96bf9450abbbc00593bc7c8a8": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d27389522e9c437695f0e93a0ecf1f09",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_16b0f13d883d48809d4703704f43204c",
      "value": "adapter_model.safetensors:‚Äá"
     }
    },
    "a4a6ed211ca44d509cb82311c27caba3": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a6784a8092dd4652bb19a142b05986b1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3267638f39f34833955764925bc59ad9",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7a23197e84e449a6b77b893f4bcc81fb",
      "value": 1
     }
    },
    "b62cf033432f40e0a9ee259515167b51": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d2117400d4744ac498d1582a3336f905",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_36e5a40703714c76ba41451af838a1fe",
      "value": "README.md:‚Äá100%"
     }
    },
    "c0a6e820a2eb41dc9c6244f614272ef5": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c7a2e8fad27e4fa2b9c80a970002d6bd": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d2117400d4744ac498d1582a3336f905": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d27389522e9c437695f0e93a0ecf1f09": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d6ef70581b8841d4b7455f1074373478": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d937f93cbe12423d9198d740769eaaad": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d9f595f07ea14377ad4f2af81b3dc236": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "de7e5ca6727c4c0d99522d35981a4ad2": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a4a6ed211ca44d509cb82311c27caba3",
      "placeholder": "‚Äã",
      "style": "IPY_MODEL_c7a2e8fad27e4fa2b9c80a970002d6bd",
      "value": "‚Äá176M/?‚Äá[00:02&lt;00:00,‚Äá82.4MB/s]"
     }
    },
    "e08504a1906e41bf8cfe2e7d231e0f2f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
